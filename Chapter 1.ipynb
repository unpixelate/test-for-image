{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d64f4c",
   "metadata": {},
   "source": [
    "# INTRODUCTION TO ARTIFICIAL INTELLIGENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814eb22-89ce-4b0d-a4c9-ea83cb2e1c44",
   "metadata": {},
   "source": [
    "## 1.1 Introduction\n",
    "\n",
    "https://medium.com/@upGrad/introduction-to-ai-history-components-pros-cons-examples-applications-c626692fcc86\n",
    "\n",
    "Intelligence refers to the capability of acquiring knowledge and applying them to solve difficult challenges. Humans are\n",
    "highly intelligent beings that have been learning about and developing solutions to various problems for many centuries.\n",
    "Artificial intelligence is humanity’s attempt to replicate this powerful innate ability to learn in our machines.\n",
    "Machines that can learn by themselves would be able to deepen their knowledge and make better decisions. Furthermore,\n",
    "combining artificial intelligence with robotics would allow us to benefit from the increased efficiency and automation of\n",
    "manual labour that it brings.\n",
    "\n",
    "Through the use of artificial intelligence, it would be possible to develop solutions which are able to function autonomously\n",
    "without requiring human intervention.\n",
    "\n",
    "The field of artificial intelligence is very broad and covers a multitude of topics. There are many different types of basic\n",
    "intelligence that is present in humans which artificial intelligence engineers hope to be able to recreate in their creations\n",
    "such as:\n",
    "\n",
    "- Visual-spatial intelligence\n",
    "- Lingustic intelligence\n",
    "- Logical intelligence\n",
    "- Bodily-Kinesthetic intelligence\n",
    "- Interpersonal intelligence\n",
    "\n",
    "\n",
    "![test2](https://raw.githubusercontent.com/unpixelate/test-for-image/main/mltask.png)\n",
    "\n",
    "The main tasks of AI and be classified as shown on the image above. Developing artificial intelligence solutions require a high amount of upfront investment to prepare and clean the data. In\n",
    "order to develop a useful model, the data collected much first be prepared in a way that these algorithms can use them, feature extraction has to be performed to sieve out useful features, followed by model training and eventually model testing.\n",
    "\n",
    "These algorithms can be developed for a wide variety of tasks across diffferent data types as well. Some examples of tasks\n",
    "that can be used by artificial intelligence algorithms are:\n",
    "\n",
    "1. Image recognition\n",
    "2. Voice recognition\n",
    "3. Optical character recognition\n",
    "4. Intelligent data analysis\n",
    "5. Customized data types\n",
    "6. Sensory data analysis\n",
    "\n",
    "![](https://raw.githubusercontent.com/unpixelate/test-for-image/main/Illustrating-the-different-categories-of-machine-learning-tasks-a-In-classification.png)\n",
    "\n",
    "Artificial intelligence algorithms are commonly applied to solve one of 4 different types of problems:\n",
    "\n",
    "1. Classification\n",
    "Classification tasks are used in categorizing the input data. The algorithms aim to categorize the data into various\n",
    "pre-defined categories which could be binary (e.g. spam vs not spam) or multiclass such as (e.g. dog, cat, bird,\n",
    "fish).\n",
    "2. Regression\n",
    "Regression tasks are used to predict real or continuous values such as age and salary. Further analysis can be done\n",
    "to understand how the dependent variable will be impacted by the independent variable.\n",
    "3. Clustering\n",
    "Clustering aims to group datapoints into certain groups based on how similar they are from one another. It is\n",
    "generally an unsupervised learning problem and aims to identify naturally occuring patterns in the data.\n",
    "4. Anomaly detection\n",
    "Anomaly detection aims to identify anomalies by learning what is normal and predicting all things that fall out of\n",
    "normality as abnormal. Anomalies may not occur very often and so specialized techniques are developed to try to solve these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdcc4fc-8faa-4eea-a940-11fd66e5d215",
   "metadata": {},
   "source": [
    "## 1.2 History of Artificial Intelligence\n",
    "\n",
    "http://beamlab.org/deeplearning/2017/02/23/deep_learning_101_part1.html\n",
    "\n",
    "Brief History of AI\n",
    "AI as a field of study can be traced back to the mid-20th century, with notable milestones and advancements along the way. Here are some key moments in AI's history:\n",
    "\n",
    "- 1950s: Alan Turing proposes the Turing Test, which is designed to determine if a machine can exhibit intelligent behavior indistinguishable from that of a human.\n",
    "John McCarthy coins the term \"Artificial Intelligence\" and, together with Marvin Minsky, Nathaniel Rochester, and Claude Shannon, organizes the famous Dartmouth Conference, which marks the birth of AI as a field of study.\n",
    "\n",
    "- 1960s: Early AI research focuses on developing symbolic reasoning systems, such as General Problem Solver by Allen Newell and Herbert A. Simon, which attempts to mimic human problem-solving techniques.\n",
    "ELIZA, a natural language processing program developed by Joseph Weizenbaum, demonstrates the potential of AI to understand and generate human-like conversation.\n",
    "\n",
    "- 1970s: AI research faces challenges due to a lack of computational power and limited knowledge representation techniques.\n",
    "However, new approaches emerge, such as rule-based systems, which give rise to expert systems like MYCIN, developed by Edward Shortliffe, that can diagnose bacterial infections and recommend treatments.\n",
    "\n",
    "- 1980s: The resurgence of AI research is fueled by increased funding and the development of machine learning techniques.\n",
    "The introduction of backpropagation algorithm leads to advancements in neural networks and the development of the Connectionist approach, which focuses on simulating brain-like networks for learning and problem-solving.\n",
    "\n",
    "- 1990s: AI research explores hybrid approaches that combine rule-based systems with machine learning techniques.\n",
    "The emergence of the World Wide Web opens up new possibilities for AI applications, such as search engines and recommendation systems.\n",
    "\n",
    "- 2000s: AI research benefits from the exponential growth in computational power and the availability of massive datasets.\n",
    "IBM's Deep Blue defeats the reigning world chess champion Garry Kasparov, highlighting the potential of AI systems in complex problem-solving.\n",
    "Apple's Siri, a virtual assistant that uses natural language processing and machine learning, is introduced, marking a significant milestone in AI's integration into everyday technology.\n",
    "2010s. The development of deep learning techniques leads to breakthroughs in image and speech recognition, natural language processing, and reinforcement learning.\n",
    "Google DeepMind's AlphaGo defeats the world champion Go player, demonstrating AI's ability to learn complex strategies and make creative decisions.\n",
    "AI applications grow exponentially, with self-driving cars, virtual assistants, and recommendation systems becoming more sophisticated and pervasive.\n",
    "\n",
    "![](https://raw.githubusercontent.com/unpixelate/test-for-image/main/nn_timeline.jpg)\n",
    "\n",
    "The brief history of deep learning can be summarised in the following image with the key events highlighted as well. \n",
    "\n",
    "A Short History of Deep Learning\n",
    "\n",
    "Deep Learning, a subset of machine learning, has its roots in the development of artificial neural networks. It focuses on creating models with multiple layers of neurons to learn hierarchical representations of the input data, enabling these models to solve complex problems more efficiently. Here is a brief timeline of the key milestones in deep learning's history:\n",
    "\n",
    "- 1940s-1950s: McCulloch-Pitts Neurons: Warren McCulloch and Walter Pitts introduce a simplified model of a biological neuron, laying the foundation for early neural network research.\n",
    "Perceptron: Frank Rosenblatt develops the perceptron algorithm, an early single-layer neural network capable of solving linearly separable problems.\n",
    "\n",
    "- 1960s-1970s: Multilayer Perceptrons: The idea of stacking multiple layers of perceptrons to create more complex networks is explored.\n",
    "Backpropagation: Paul Werbos introduces the backpropagation algorithm for training multilayer perceptrons, although its significance is not fully recognized at the time.\n",
    "\n",
    "- 1980s-1990s: Backpropagation Rediscovered: Geoffrey Hinton, David Rumelhart, and Ronald Williams popularize the backpropagation algorithm, which becomes the standard method for training neural networks.\n",
    "Convolutional Neural Networks: Yann LeCun and his collaborators develop the LeNet-5 architecture, an early example of a convolutional neural network (CNN) that can recognize handwritten digits.\n",
    "\n",
    "- 2000s: Recurrent Neural Networks: Long Short-Term Memory (LSTM) networks, a type of recurrent neural network (RNN) developed by Sepp Hochreiter and Jürgen Schmidhuber, gain popularity for their ability to learn long-range dependencies in sequential data.\n",
    "Deep Belief Networks: Geoffrey Hinton and his collaborators introduce deep belief networks, which combine unsupervised pre-training with supervised fine-tuning, improving the performance of deep neural networks.\n",
    "- 2010s: ImageNet Competition: Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton develop AlexNet, a deep CNN that significantly outperforms other models in the ImageNet Large Scale Visual Recognition Challenge, marking a turning point for deep learning in computer vision.\n",
    "Generative Adversarial Networks: Ian Goodfellow and his collaborators introduce generative adversarial networks (GANs), a novel framework for training generative models that can create realistic images, texts, and other data. Transformer Networks: Vaswani et al. propose the Transformer architecture, which uses self-attention mechanisms to achieve state-of-the-art performance in natural language processing tasks, leading to the development of models like BERT, GPT, and T5.\n",
    "\n",
    "The rapid advancements in deep learning have led to its widespread adoption in various domains, including computer vision, natural language processing, speech recognition, and reinforcement learning. As research continues, we can expect further breakthroughs and applications in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9edc1-5451-47d3-8a55-6bc2ba51b1a8",
   "metadata": {},
   "source": [
    "## 1.3 Strengths and Weaknesses of Artificial Intelligence\n",
    "\n",
    "\n",
    "![test](https://raw.githubusercontent.com/unpixelate/test-for-image/main/Advantages-and-Disadvantages.jpg)\n",
    "\n",
    "Strengths of Artificial Intelligence\n",
    "\n",
    "- Speed and Efficiency: AI systems can process vast amounts of data and perform complex calculations much faster than humans. For example, AI-powered recommendation engines can quickly analyze user behavior and preferences to provide personalized content or product suggestions.\n",
    "- Automation: AI can automate repetitive and time-consuming tasks, freeing up human resources for more creative or strategic work. In manufacturing, AI-powered robots can perform assembly line tasks with high precision and efficiency.\n",
    "- Data Analysis: AI algorithms can identify patterns and trends in large datasets, enabling better decision-making and prediction capabilities. For instance, AI-driven analytics in healthcare can help detect diseases at an early stage or predict patient outcomes more accurately.\n",
    "- Reliability and Consistency: AI systems can operate without fatigue, maintaining consistent performance over time. In quality control, AI-powered inspection systems can consistently identify defects in products, reducing the likelihood of human error. \n",
    "- Adaptability: AI systems can learn and adapt to new situations or changing environments. Self-driving cars, for example, can adjust their driving behavior based on real-time traffic conditions and other factors.\n",
    "\n",
    "Weaknesses of Artificial Intelligence\n",
    "\n",
    "- Lack of Emotional Intelligence: AI systems currently lack the ability to understand and respond to emotions, which can limit their effectiveness in certain human-centric tasks, such as customer service or therapy.\n",
    "- Limited Creativity: AI's creativity is constrained by the data it has been trained on and the algorithms used. While AI can generate art or music, its creations may lack the depth and originality of human-made works.\n",
    "- Ethical and Social Concerns: AI applications can raise ethical and social issues, such as privacy invasion, job displacement, and biased decision-making. Facial recognition technology, for example, has raised concerns about surveillance and potential misuse.\n",
    "- Dependency on Data: AI systems rely heavily on data for learning and decision-making, which can lead to problems if the data is incomplete, biased, or outdated. AI models trained on biased data can perpetuate or exacerbate existing biases, as seen in some cases of biased hiring algorithms.\n",
    "- High Development and Maintenance Costs: Developing and maintaining AI systems can be expensive, particularly for complex deep learning models that require specialized hardware and expertise. This can limit the accessibility of AI technology for smaller organizations or under-resourced sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee342374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
